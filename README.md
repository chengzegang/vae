# Variational AutoEncoder

-----

**Table of Contents**

- [Variational AutoEncoder](#variational-autoencoder)
  - [Introduction](#introduction)
  - [TODO: Checkpoints](#todo-checkpoints)
  - [License](#license)

## Introduction

This is an Pytorch implementation of Variational AutoEncoder

## TODO: Checkpoints

| Checkpoint | Description |
| :--------: | :---------: |
| vae-256-64-laion5b.pt | 256x256 resolution, 64 latent dimensions, trained on Laion5B |
| vae-256-16-laion5b.pt | 256x256 resolution, 16 latent dimensions, trained on Laion5B |
| vae-256-4-laion5b.pt | 256x256 resolution, 4 latent dimensions, trained on Laion5B |
## License

`vae` is distributed under the terms of the [MIT](https://spdx.org/licenses/MIT.html) license.
